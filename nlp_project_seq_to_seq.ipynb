{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVeUQlYnxuZJ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "def clean_text(column):\n",
        "    for row in column:\n",
        "# Split CamelCase Characters like ConcatenationOperator to Concatenation Operator\n",
        "        row = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1',  str(row))).split()\n",
        "        row = ' '.join(row)\n",
        "# Replace tabs and newlines with a single space\n",
        "        row = re.sub(\"(\\\\t)\", \" \", str(row)).lower()\n",
        "        row = re.sub(\"(\\\\r)\", \" \", str(row)).lower()\n",
        "        row = re.sub(\"(\\\\n)\", \" \", str(row)).lower()\n",
        "# Remove the special characters and numbers \n",
        "        row = re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",.\\}`$\\{;@?~*!+=_\\//1234567890]\", \" \", str(row)).lower()\n",
        "# Remove Repeated words\n",
        "        row = re.sub(r\"\\\\b(\\\\w+)(?:\\\\W+\\\\1\\\\b)+\", \"\", str(row)).lower()\n",
        "# Remove punctuation at the end of a word\n",
        "        row = re.sub(\"(\\.\\s+)\", \" \", str(row)).lower()\n",
        "        row = re.sub(\"(\\-\\s+)\", \" \", str(row)).lower()\n",
        "        row = re.sub(\"(\\:\\s+)\", \" \", str(row)).lower()\n",
        "# Remove multiple spaces\n",
        "        row = re.sub(\"(\\s+)\", \" \", str(row)).lower()\n",
        "# Remove the single character (any character) between any two spaces\n",
        "        row = re.sub(\"(\\s+.\\s+)\", \" \", str(row)).lower()\n",
        "        yield row"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_code = pd.read_csv('/content/drive/MyDrive/nlp/project/ALGO_ZENITH_BOOTCAMP_DATASET/javascript_Sample_Dataset.csv')\n",
        "#extract only the code and docstring columns\n",
        "df_code_p = df_code[[\"code\",\"docstring\"]]\n",
        "print (df_code_p[\"docstring\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuVDcuMyyKup",
        "outputId": "c3bd1a6c-529b-4423-9672-02d3451e9ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Find the next separator: space, parens, comma, colon, double-quote, dollar, brackets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#call clean_text function\n",
        "processed_code= clean_text(df_code_p['code'])\n",
        "processed_summary = clean_text(df_code_p['docstring'])\n",
        "import spacy\n",
        "from time import time\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n",
        "# Process the text as batches, you may should the batchsize when you use the complete dataset, empirically can be set to 5000 for > 1,00,000 records\n",
        "code = [str(doc) for doc in nlp.pipe(processed_code, batch_size=50)]\n",
        "#_START_ and _END_ tokens are markers to understand start and end of summaries\n",
        "summary = [ str(doc) for doc in nlp.pipe(processed_summary, batch_size=50)]"
      ],
      "metadata": {
        "id": "KQ2T0c-ayRDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab3e4e8-596c-45f5-a400-a9ac5102ccb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1899: UserWarning: [W123] Argument disable with value ['ner', 'parser'] is used instead of ['senter'] as specified in the config. Be aware that this might affect other components in your pipeline.\n",
            "  config_value=config[\"nlp\"][key],\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_count=[]\n",
        "for sent in df_code_p['code']:\n",
        "    code_count.append(len(sent.split()))"
      ],
      "metadata": {
        "id": "OXCaj8P8yYCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "UHqC9SN9z5St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_df = pd.DataFrame()\n",
        "histogram_df['code'] = code_count\n",
        "histogram_df.hist(bins = 10)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "X1I2fzhYyciF",
        "outputId": "4bd72f64-c6b9-4673-c685-dfd5f1b5317f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_code_len = 100\n",
        "max_summary_len =25\n",
        "# Extract the codes and summaries within the maximum length\n",
        "import numpy as np\n",
        "cleaned_code = np.array(df_code_p['code'])\n",
        "cleaned_summary= np.array(df_code_p['docstring'])\n",
        "short_text = []\n",
        "short_summary = []\n",
        "for i in range(len(cleaned_code)):\n",
        "  if len(cleaned_summary[i].split()) <= max_summary_len and len(cleaned_code[i].split()) <= max_code_len:\n",
        "    short_text.append(cleaned_code[i])\n",
        "    short_summary.append(cleaned_summary[i])\n",
        "    post_code = pd.DataFrame({'code': short_text,'summary': short_summary})\n",
        "    post_code.head(100)\n",
        "    #apply start and end markers\n",
        "    post_code['summary'] = post_code['summary'].apply(lambda x: 'sostok ' + x \\\n",
        "    + ' eostok')\n",
        "post_code.head(2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "nM0H_boYyih7",
        "outputId": "5c09f264-f241-49e2-fd87-81ef95070580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                code  \\\n",
              "0  function show(url) {\\n  const location = get('...   \n",
              "1  function(_url,_href){\\n            if (!_url) ...   \n",
              "\n",
              "                                    summary  \n",
              "0                        sostok show eostok  \n",
              "1  sostok check event need delegated eostok  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-335fb1e8-8aa1-49ef-90a2-32faac90ab47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>function show(url) {\\n  const location = get('...</td>\n",
              "      <td>sostok show eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>function(_url,_href){\\n            if (!_url) ...</td>\n",
              "      <td>sostok check event need delegated eostok</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-335fb1e8-8aa1-49ef-90a2-32faac90ab47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-335fb1e8-8aa1-49ef-90a2-32faac90ab47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-335fb1e8-8aa1-49ef-90a2-32faac90ab47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "id": "joZsYKPU2XL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t  = Tokenizer()\n",
        "\n",
        "fit_text = 'Machine Learning'\n",
        "\n",
        "t.fit_on_texts(fit_text)\n",
        "\n",
        "print(\"Count of characters:\",t.word_counts)\n",
        "print(\"Length of text:\",t.document_count)\n",
        "print(\"Character index\",t.word_index)\n",
        "print(\"Frequency of characters:\",t.word_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvQZXrwI1cfB",
        "outputId": "a1e71cb7-37bc-4b81-ff58-bc24ad3242aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of characters: OrderedDict([('m', 1), ('a', 2), ('c', 1), ('h', 1), ('i', 2), ('n', 3), ('e', 2), ('l', 1), ('r', 1), ('g', 1)])\n",
            "Length of text: 16\n",
            "Character index {'n': 1, 'a': 2, 'i': 3, 'e': 4, 'm': 5, 'c': 6, 'h': 7, 'l': 8, 'r': 9, 'g': 10}\n",
            "Frequency of characters: defaultdict(<class 'int'>, {'m': 1, 'a': 2, 'c': 1, 'h': 1, 'i': 2, 'n': 3, 'e': 2, 'l': 1, 'r': 1, 'g': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_validation, y_train, y_validation = train_test_split(\n",
        "np.array(post_code[\"code\"]),\n",
        "np.array(post_code[\"summary\"]),\n",
        "test_size=0.15,\n",
        "random_state=0,\n",
        "shuffle=True,\n",
        ")"
      ],
      "metadata": {
        "id": "YsgfKuk_1mLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a tokenizer on training data\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_train))\n",
        "threshold = 2\n",
        "cnt_infrequent = 0\n",
        "total_cnt = 0\n",
        "for key, value in x_tokenizer.word_counts.items():\n",
        "    total_cnt = total_cnt + 1\n",
        "    if value < threshold:\n",
        "       cnt_infrequent = cnt_infrequent + 1\n",
        "print(\"% of not frequent words in vocabulary: \", (cnt_infrequent / total_cnt) * 100)\n",
        "# Remove the infrequent words\n",
        "x_tokenizer = Tokenizer(num_words = total_cnt - cnt_infrequent)\n",
        "x_tokenizer.fit_on_texts(list(x_train))\n",
        "# Convert the code sequences to integer sequences (integer numbers ranging from 1 to the maximum vocab sizes)\n",
        "x_train_seqs = x_tokenizer.texts_to_sequences(x_train)\n",
        "x_validation_seqs = x_tokenizer.texts_to_sequences(x_validation)\n",
        "# printing the integer sequences\n",
        "print (x_train_seqs)\n",
        "\n",
        "# Pad zero upto maximum length\n",
        "x_train = pad_sequences(x_train_seqs,  maxlen=max_code_len, padding='post')\n",
        "x_validation = pad_sequences(x_validation_seqs, maxlen=max_code_len, padding='post')\n",
        "# Size of vocabulary (+1 for padding token)\n",
        "x_voc = x_tokenizer.num_words + 1\n",
        "print(\"Size of vocabulary in X = {}\".format(x_voc))\n",
        "\n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_train))\n",
        "threshold = 2\n",
        "cnt_infrequent = 0\n",
        "total_cnt = 0\n",
        "for key, value in y_tokenizer.word_counts.items():\n",
        "    total_cnt = total_cnt + 1\n",
        "    if value < threshold:\n",
        "        cnt_infrequent = cnt_infrequent + 1\n",
        "y_tokenizer = Tokenizer(num_words = total_cnt - cnt_infrequent)\n",
        "y_tokenizer.fit_on_texts(list(y_train))\n",
        "y_train_seqs = y_tokenizer.texts_to_sequences(y_train)\n",
        "y_validation_seqs = y_tokenizer.texts_to_sequences(y_validation)\n",
        "y_train = pad_sequences(y_train_seqs,  maxlen=max_summary_len, padding='post')\n",
        "y_validation = pad_sequences(y_validation_seqs, maxlen=max_summary_len, padding='post')\n",
        "y_voc = y_tokenizer.num_words + 1\n",
        "print(\"Size of vocabulary in Y = {}\".format(y_voc))\n",
        "\n",
        "print(len(x_train))\n",
        "print(len(y_train))\n",
        "print(len(x_validation))\n",
        "print(len(y_validation))\n",
        "# vocab sizes for x and y are 356 ans 105, hence highest integer value would be less than that. Also the maximum lengths of x and y are different\n",
        "print((x_train[0]))\n",
        "print((y_train[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2xZU9pv1nRR",
        "outputId": "98d1deba-61dd-4574-e2f0-d673bf88a240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of not frequent words in vocabulary:  44.2159383033419\n",
            "[[3, 129, 130, 2, 20, 73, 20, 131, 132, 132, 131, 129, 38, 130, 23, 9, 9], [3, 39, 74, 24, 39, 39, 2, 21, 133, 39, 39, 39, 4, 21, 19, 21, 39, 3, 134, 4, 134, 74, 24], [3, 135, 5, 14, 28, 21, 55, 135, 3, 75, 2, 75, 4, 2, 14, 14, 75, 40, 14, 136, 14, 75, 4, 14], [3, 137, 138, 56, 1, 35, 137, 138, 1, 56, 56], [3, 46, 2, 29, 46, 47, 1, 139, 46, 2, 1, 48, 4, 76, 5, 140, 1, 1, 100, 1, 100, 141, 1, 1, 48, 1, 100, 19, 1, 140, 4, 49], [3, 15, 101, 102, 36, 5, 77, 15, 142, 143, 2, 101, 15, 102, 36, 30, 25, 144, 145, 146, 147, 41, 103, 148, 3, 78, 149, 42, 150, 151, 152, 153, 154, 155, 156, 157, 78, 158, 77, 9, 102, 159, 101, 104, 15, 15, 19, 77, 79, 104, 15, 15, 141, 77, 79, 160, 15, 23, 79, 57, 161, 14, 15, 36, 36], [3, 10, 2, 10, 4, 1, 10, 56, 80, 10, 41, 26, 21, 55, 3, 6, 2, 10, 6, 4, 1, 10, 6, 10, 6, 10, 6, 1], [3, 1, 162, 49, 1, 162, 55, 1, 58, 1, 1, 31, 103, 59, 1, 55, 1, 58, 1, 1], [3, 81, 5, 163, 81, 1, 10, 81, 1, 10, 164, 163, 3, 10, 1, 10, 50, 82, 1, 4, 1], [3, 83, 5, 6, 84, 6, 26, 1, 10, 2, 1, 10, 105, 6, 1, 10, 6, 1, 165, 6, 83, 4, 1], [3, 2, 26, 16, 2, 26, 16, 20, 57, 51, 60, 43, 166, 16, 20, 166, 2, 26, 16, 20, 57, 51, 60, 43, 106, 16, 20, 106, 2, 26, 16, 20, 84, 5, 6, 26, 16, 20, 167, 57, 51, 43, 106, 9, 6, 16, 20, 167, 6], [3, 19, 5, 6, 84, 6, 26, 19, 2, 19, 105, 6, 1, 165, 6, 19, 6, 4, 1], [3, 27, 1, 27, 27, 1, 49, 25, 1, 168], [3, 169, 2, 29, 1, 170, 47, 1, 170, 40, 2, 29, 1, 171, 47, 1, 171, 40, 2, 29, 1, 172, 47, 1, 172, 40, 2, 29, 1, 173, 47, 1, 173, 40, 30, 35, 25, 31, 169], [3, 174, 5, 85, 174, 9, 9, 5, 61, 85, 175, 107, 85, 108, 61, 61, 61, 85, 175, 4, 61], [3, 37, 27, 5, 44, 27, 44, 107, 37, 2, 37, 176, 44, 177, 37, 27, 37, 37], [3, 52, 52, 52, 178, 49, 52, 1, 86, 52, 4, 52], [3, 87, 21, 164, 87, 3, 22, 2, 22, 109, 179, 110, 180, 87, 5, 11, 181, 22, 2, 179, 182, 183, 11, 22, 4, 32, 80, 11, 2, 180, 182, 183, 11, 22, 4, 32, 80, 11, 4, 32, 20, 31, 22, 22], [3, 19, 5, 6, 84, 6, 26, 19, 2, 19, 105, 6, 1, 6, 19, 6, 4, 1], [3, 11, 2, 11, 24, 32, 26, 11, 11, 111, 4, 76, 4, 29, 11, 111, 11, 111], [3, 62, 2, 133, 62, 4, 62, 184, 185, 82, 40, 2, 62, 4, 62, 27], [3, 63, 186, 5, 6, 186, 9, 9, 32, 6, 32, 6, 5, 8, 63, 8, 112, 187, 63, 22, 107, 32, 6, 8, 8, 9, 9, 8, 32, 6, 8, 63, 63, 8, 8], [3, 64, 88, 2, 64, 4, 5, 53, 50, 41, 64, 1, 53, 5, 89, 1, 53, 22, 88, 53, 88, 4, 1, 1, 89], [3, 33, 17, 188, 2, 33, 8, 17, 8, 2, 188, 5, 12, 35, 25, 65, 12, 33, 12, 17, 30, 12, 81, 5, 14, 8, 17, 8, 33, 8, 66, 17, 66, 17, 66, 33, 66, 65, 17, 65, 17, 65, 33, 65, 51, 33, 51, 17, 51, 2, 33, 67, 17, 67, 14, 67, 33, 67, 17, 67, 4, 14], [3, 1, 68, 90, 189, 12, 43, 190, 91, 191, 113, 92, 192, 12, 1, 68, 69, 12, 1, 193, 69, 90, 194, 195, 1, 34, 195, 1, 28, 2, 1, 34, 196, 1, 1, 34, 197, 12, 43, 53, 91, 12, 1, 68, 1, 114, 1, 34, 197, 12, 43, 53, 91, 192, 12, 1, 114, 69, 1, 34, 196, 198, 1, 68, 198, 1, 114, 90, 199, 115, 43, 190, 91, 191, 113, 92, 115, 1, 68, 69, 115, 1, 193, 69, 194, 189, 200, 199], [3, 181, 45, 5, 11, 2, 29, 45, 109, 11, 45, 109, 11, 22, 112, 45, 116, 45, 116, 184, 45, 116, 9, 9, 112, 187, 45, 22, 4, 11], [3, 117, 118, 1, 201, 28, 119, 1, 117, 117, 1, 118, 118, 1, 28, 1, 23, 1, 82, 1, 23, 1, 76, 1, 1, 23], [3, 37, 27, 5, 44, 27, 44, 37, 3, 60, 2, 60, 176, 44, 177, 60, 27], [3, 70, 1, 201, 28, 119, 2, 13, 54, 30, 35, 25, 13, 54, 93, 31, 42, 94, 95, 13, 70, 2, 13, 38, 30, 35, 25, 13, 38, 93, 31, 42, 94, 95, 13, 70, 2, 13, 54, 202, 13, 54, 203, 13, 54, 204, 30, 35, 25, 13, 54, 92, 202, 203, 110, 204, 93, 31, 42, 94, 95, 13, 70, 2, 13, 38, 205, 13, 38, 206, 30, 35, 25, 13, 38, 92, 205, 110, 206, 93, 31, 42, 94, 95, 13, 70], [3, 96, 24, 24, 24, 24, 24, 5, 96, 24, 74, 32, 74, 87, 2, 96, 30, 35, 25, 66, 9, 24, 4, 96], [3, 46, 2, 29, 46, 47, 1, 139, 46, 2, 1, 48, 1, 48, 1, 48, 55, 1, 1, 48, 23, 2, 1, 1, 49, 4, 76, 1, 4, 49], [3, 120, 73, 120, 178, 207, 42, 185, 207, 5, 208, 168, 119, 120, 208], [3, 209, 97, 121, 97, 19, 122, 56, 5, 34, 97, 122, 159, 29, 34, 104, 97, 122, 34, 79, 160, 209, 34], [3, 123, 5, 16, 210, 123, 124, 98, 86, 123, 211, 98, 86, 16, 2, 124, 16, 4, 5, 7, 99, 124, 59, 7, 108, 16, 7, 99, 7, 17, 16, 212, 7, 108, 16, 7, 211, 7, 59, 136, 212, 28, 7, 17], [3, 125, 126, 36, 5, 127, 128, 15, 12, 23, 142, 143, 2, 125, 36, 30, 25, 144, 145, 146, 147, 128, 126, 38, 41, 126, 23, 41, 103, 148, 3, 78, 149, 42, 150, 151, 152, 153, 154, 155, 156, 157, 78, 158, 127, 9, 125, 15, 127, 128, 73, 20, 9, 9, 15, 200, 98, 15, 23, 12, 98, 57, 161, 14, 15, 12, 12, 36, 36], [3, 71, 8, 5, 72, 1, 10, 72, 41, 7, 18, 44, 121, 5, 7, 18, 71, 8, 8, 82, 2, 21, 71, 7, 71, 7, 7, 18, 71, 59, 41, 18, 2, 21, 213, 18, 18, 3, 89, 83, 1, 214, 89, 215, 28, 99, 83, 58, 1, 18, 40, 2, 21, 216, 18, 18, 18, 23, 3, 7, 5, 14, 7, 59, 2, 21, 213, 14, 1, 214, 14, 215, 28, 99, 7, 28, 58, 1, 80, 18, 31, 210, 2, 21, 216, 18, 7, 2, 72, 7, 1, 7, 1, 58, 1, 72, 7, 72, 7, 8, 18], [3, 64, 90, 50, 86, 2, 50, 73, 113, 31, 50, 121, 4, 50, 88, 64]]\n",
            "Size of vocabulary in X = 218\n",
            "Size of vocabulary in Y = 61\n",
            "37\n",
            "37\n",
            "7\n",
            "7\n",
            "[  3 129 130   2  20  73  20 131 132 132 131 129  38 130  23   9   9   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "OV4gI6hR27Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "yRVxo5XpnNBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeDistributed(nn.Module):\n",
        "    def __init__(self, module, batch_first=False):\n",
        "        super(TimeDistributed, self).__init__()\n",
        "        self.module = module\n",
        "        self.batch_first = batch_first\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if len(x.size()) <= 2:\n",
        "            return self.module(x)\n",
        "\n",
        "        # Squash samples and timesteps into a single axis\n",
        "        x_reshape = x.contiguous().view(-1, x.size(-1))  # (samples * timesteps, input_size)\n",
        "\n",
        "        y = self.module(x_reshape)\n",
        "\n",
        "        # We have to reshape Y\n",
        "        if self.batch_first:\n",
        "            y = y.contiguous().view(x.size(0), -1, y.size(-1))  # (samples, timesteps, output_size)\n",
        "        else:\n",
        "            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "hDxciDDSL2_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, x_voc,y_voc,latent_dim,embedding_dim):\n",
        "        super(EncoderDecoder,self).__init__()\n",
        "        self.x_voc=x_voc\n",
        "        self.y_voc=y_voc\n",
        "        self.lstm_size = latent_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_layers = 3\n",
        "\n",
        "        # n_vocab = len(dataset.uniq_words)\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=self.x_voc,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.4,\n",
        "        )\n",
        "\n",
        "        self.dec_emb_layer = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x,y, prev_state):\n",
        "        embed_x = self.embedding(x)\n",
        "        output_x, state_x = self.lstm(embed_x,prev_state)\n",
        "        embed_y=self.embedding(y)\n",
        "        output_y,state=self.lstm(embed_y,state_x,num_layers=1)\n",
        "        output=self.fc(output_y)\n",
        "\n",
        "        # logits = output\n",
        "        return output, state\n",
        "\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))"
      ],
      "metadata": {
        "id": "EIqai89xunro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wc-P3IHOwOHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 300\n",
        "embedding_dim = 200\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_code_len, ))\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim,\n",
        "trainable=True)(encoder_inputs)\n",
        "# Encoder LSTM 1\n",
        "encoder_lstm1 = LSTM(latent_dim, return_sequences=True,\n",
        "return_state=True, dropout=0.4,\n",
        "recurrent_dropout=0.4)\n",
        "(encoder_output1, state_h1, state_c1) = encoder_lstm1(enc_emb)\n",
        "# Encoder LSTM 2\n",
        "encoder_lstm2 = LSTM(latent_dim, return_sequences=True,\n",
        "return_state=True, dropout=0.4,\n",
        "recurrent_dropout=0.4)\n",
        "(encoder_output2, state_h2, state_c2) = encoder_lstm2(encoder_output1)\n",
        "# Encoder LSTM 3\n",
        "encoder_lstm3 = LSTM(latent_dim, return_state=True,\n",
        "return_sequences=True, dropout=0.4,\n",
        "recurrent_dropout=0.4)\n",
        "(encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_output2)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "# Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# Decoder LSTM\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True,\n",
        "return_state=True, dropout=0.4,\n",
        "recurrent_dropout=0.2)\n",
        "(decoder_outputs, decoder_fwd_state, decoder_back_state) = \\\n",
        "decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "SizUI4TA3Tt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "history = model.fit(\n",
        "[x_train, y_train[:, :-1]],\n",
        "y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:],\n",
        "epochs=50,\n",
        "callbacks=[es],\n",
        "batch_size=128,\n",
        "validation_data=([x_validation, y_validation[:, :-1]],\n",
        "y_validation.reshape(y_validation.shape[0], y_validation.shape[1], 1)[:\n",
        ", 1:]),\n",
        ")"
      ],
      "metadata": {
        "id": "Ei0-3xOg3Uyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_target_word_index = y_tokenizer.index_word\n",
        "reverse_source_word_index = x_tokenizer.index_word\n",
        "target_word_index = y_tokenizer.word_index\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs,\n",
        "state_h, state_c])\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
        "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
        "decoder_hidden_state_input = Input(shape=(max_code_len, latent_dim))\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "(decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
        "initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "# Final decoder model\n",
        "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "metadata": {
        "id": "jof8Grma3ls8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # Encode the input as state vectors.\n",
        "  (e_out, e_h, e_c) = encoder_model.predict(input_seq)\n",
        "  # Generate empty target sequence of length 1\n",
        "  target_seq = np.zeros((1, 1))\n",
        "  # Populate the first word of target sequence with the start word.\n",
        "  target_seq[0, 0] = target_word_index['sostok']\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "      (output_tokens, h, c) = decoder_model.predict([target_seq]+ [e_out, e_h, e_c])\n",
        "  # Sample a token\n",
        "      sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "      sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "      if sampled_token != 'eostok':\n",
        "          decoded_sentence += ' ' + sampled_token\n",
        "    # Exit condition: either hit max length or find the stop word.\n",
        "      if sampled_token == 'eostok' or len(decoded_sentence.split()) >= max_summary_len - 1:\n",
        "          stop_condition = True\n",
        "    # Update the target sequence (of length 1)\n",
        "      target_seq = np.zeros((1, 1))\n",
        "      target_seq[0, 0] = sampled_token_index\n",
        "    # Update internal states\n",
        "      (e_h, e_c) = (h, c)\n",
        "  return decoded_sentence"
      ],
      "metadata": {
        "id": "N6PTiiIb3mnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString = ''\n",
        "    for i in input_seq:\n",
        "        if i != 0 and i != target_word_index['sostok'] and i \\\n",
        "        != target_word_index['eostok']:\n",
        "             newString = newString + reverse_target_word_index[i] + ' '\n",
        "    return newString\n",
        "# To convert sequence to text\n",
        "def seq2text(input_seq):\n",
        "     newString = ''\n",
        "     for i in input_seq:\n",
        "         if i != 0:\n",
        "             newString = newString + reverse_source_word_index[i] + ' '\n",
        "     return newString"
      ],
      "metadata": {
        "id": "FiebS7UJ38Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_bleu_score = 0\n",
        "diff = 0\n",
        "for i in range(len(Test_code_comment)):\n",
        "    pred = translate(transformer, Test_code_comment[i][0])\n",
        "    bleu_score = (sacrebleu.sentence_bleu(pred, [Test_code_comment[i][1]], smooth_method='exp')).score\n",
        "    print(bleu_score)\n",
        "    total_bleu_score += bleu_score\n"
      ],
      "metadata": {
        "id": "lweaOT4MoaW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total test bleu score = {total_bleu_score/(len(Test_code_comment)-diff):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNNh2SSwo2Sv",
        "outputId": "097a8c5f-a581-4171-861b-e3f0991ad8d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total test bleu score = 13.0074\n"
          ]
        }
      ]
    }
  ]
}